{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:03:38.863887Z",
     "start_time": "2025-06-01T10:03:38.827906Z"
    },
    "collapsed": true
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import os\n",
    "from rapidfuzz import fuzz\n",
    "from dateutil.parser import parse"
   ],
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43c011ce6dea5438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:03:39.529680Z",
     "start_time": "2025-06-01T10:03:39.525189Z"
    }
   },
   "outputs": [],
   "source": [
    "bank_abbreviations = {\n",
    "    \"NEFT\", \"RTGS\", \"IMPS\", \"UPI\", \"ECS\", \"NACH\", \"ACH\", \"ATM\", \"POS\", \"CHQ\", \"CLG\", \"TPT\", \"TRF\", \"IB\", \"MB\", \"VPA\", \"BIL/BILLPAY\", \"AUTOPAY\", \"SAL/SALARY\", \"DIV\", \"INT\", \"TDS\", \"REF\", \"CHRG\", \"REV\", \"PUR\", \"CASHDEP\", \"CASHWDL\", \"IB/IBFT\", \"MB/MOB\", \"BBPS\", \"CHQ NO.\", \"INST NO.\", \"TXN/TRAN\", \"REF NO.\", \"B/F\", \"C/F\", \"BOD\", \"EOD\", \"MIN BAL\", \"AMB CHG\"\n",
    "}\n",
    "\n",
    "expected_headers = {\n",
    "        \"date\": [\n",
    "            \"date\", \"txn date\", \"value date\", \"transaction date\", \"posting date\", \"tran date\",\n",
    "            \"dt\", \"trans date\", \"process date\", \"effective date\", \"book date\"\n",
    "        ],\n",
    "        \"description\": [\n",
    "            \"description\", \"narration\", \"details\", \"particulars\", \"transaction details\", \"remark\",\n",
    "            \"txn details\", \"transaction description\", \"purpose\", \"memo\", \"note\", \"comments\"\n",
    "        ],\n",
    "        \"debit\": [\n",
    "            \"debit\", \"withdrawal\", \"amount debited\", \"debit amount\", \"dr\", \"withdraw\", \"debit amt\",\n",
    "            \"dr amount\", \"paid\", \"out\", \"payment\", \"disbursement\"\n",
    "        ],\n",
    "        \"credit\": [\n",
    "            \"credit\", \"deposit\", \"amount credited\", \"credit amount\", \"cr\", \"deposit amount\", \"credit amt\",\n",
    "            \"cr amount\", \"received\", \"in\", \"receipt\", \"collection\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "noise_patterns = [\n",
    "            r'statement\\s+(of|for|period)',\n",
    "            r'account\\s+(holder|number|summary)',\n",
    "            r'customer\\s+(name|id|details)',\n",
    "            r'address\\s*:',\n",
    "            r'phone\\s*(no|number)\\s*:',\n",
    "            r'email\\s*(id|address)\\s*:',\n",
    "            r'branch\\s+(name|code|address)',\n",
    "            r'ifsc\\s*(code)?\\s*:',\n",
    "            r'opening\\s+balance',\n",
    "            r'closing\\s+balance',\n",
    "            r'total\\s+(credit|debit|transactions)',\n",
    "            r'summary\\s+(of|for)',\n",
    "            r'thank\\s+you\\s+for\\s+banking',\n",
    "            r'continued\\s+(on|from)',\n",
    "            r'page\\s+\\d+(\\s+of\\s+\\d+)?',\n",
    "            r'(generated|printed)\\s+on\\s*:',\n",
    "            r'statement\\s+period\\s*:',\n",
    "            r'customer\\s+id\\s*:',\n",
    "            r'^\\s*$',\n",
    "            r'bank\\s+(name|logo)',\n",
    "            r'terms\\s+(and|&)\\s+conditions',\n",
    "            r'disclaimer',\n",
    "            r'important\\s+notes?',\n",
    "            r'legend\\s*:',\n",
    "            r'abbreviations?\\s*:'\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852bb527bfa624c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:03:39.755429Z",
     "start_time": "2025-06-01T10:03:39.752588Z"
    }
   },
   "outputs": [],
   "source": [
    "def mask_all_digits(text):\n",
    "    return re.sub(r\"\\d{6,}\", lambda m: \"*\" * len(m.group()), text)\n",
    "\n",
    "def normalize_date(value):\n",
    "    if isinstance(value, (pd.Timestamp, datetime.datetime)):\n",
    "        return value.strftime(\"%Y-%m-%d\")\n",
    "    try:\n",
    "        return parse(str(value), fuzzy=True).strftime(\"%Y-%m-%d\")\n",
    "    except Exception:\n",
    "        print(f\"Failed to parse date from value: {value}. Please check the format or content.\")\n",
    "        return value  # return original if parsing fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f42ee21d3092e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:03:39.954361Z",
     "start_time": "2025-06-01T10:03:39.949497Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransactionValidator:\n",
    "    @staticmethod\n",
    "    def is_valid_date(value):\n",
    "        if isinstance(value, (pd.Timestamp, datetime.datetime)):\n",
    "            return True\n",
    "        if isinstance(value, (int, float)):  # reject pure numbers (likely not dates)\n",
    "            return False\n",
    "        if not isinstance(value, str):\n",
    "            return False\n",
    "\n",
    "        value = value.strip()\n",
    "        if not value or value.lower() == 'nan':\n",
    "            return False\n",
    "\n",
    "        try:\n",
    "            parse(value, fuzzy=True)  # allow embedded/extra tokens\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def is_valid_amount(value):\n",
    "        try:\n",
    "            val = float(value)\n",
    "            return not pd.isna(val) and str(value).lower() != 'nan'\n",
    "        except (ValueError, TypeError):\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def is_valid_description(value):\n",
    "        if not isinstance(value, str):\n",
    "            return False\n",
    "        value = value.strip().lower()\n",
    "        for pattern in noise_patterns:\n",
    "            if re.search(pattern, value, re.IGNORECASE):\n",
    "                return False\n",
    "        if not value or value in [\"nan\", \"date\", \"opening\", \"closing\", \"balance\"]:\n",
    "            return False\n",
    "        if re.match(r\"^(transaction|txn|narration|particulars|details|ref|id)[\\s:]*$\", value):\n",
    "            return False\n",
    "        contains_abbreviation = any(abbrev.lower() in value for abbrev in bank_abbreviations)\n",
    "        return contains_abbreviation or any(c.isalpha() for c in value)\n",
    "\n",
    "    @classmethod\n",
    "    def is_valid_transaction_row(cls, row = None):\n",
    "        values = row.astype(str).tolist()\n",
    "        non_empty_values = [val.strip() for val in values if val.strip().lower() not in ['nan', '']]\n",
    "\n",
    "        if len(non_empty_values) < 3:\n",
    "            return False\n",
    "\n",
    "        date_val = next((val for val in non_empty_values if TransactionValidator.is_valid_date(val)), None)\n",
    "        amount_val = next((val for val in non_empty_values if TransactionValidator.is_valid_amount(val)), None)\n",
    "        desc_val = next((val for val in non_empty_values if TransactionValidator.is_valid_description(val)), None)\n",
    "\n",
    "        if not (date_val and amount_val and desc_val):\n",
    "            return False\n",
    "\n",
    "        return len({str(date_val), str(amount_val), str(desc_val)}) == 3\n",
    "\n",
    "\n",
    "def robust_load(input_file):\n",
    "    print(\"🔍 Loading file:\", input_file)\n",
    "    _, ext = os.path.splitext(input_file)\n",
    "    ext = ext.lower().lstrip('.')\n",
    "    if ext == \"xlsx\":\n",
    "        return pd.read_excel(input_file, engine=\"openpyxl\", header=None)\n",
    "    elif ext == \"xls\":\n",
    "        try:\n",
    "            return pd.read_excel(input_file, engine=\"xlrd\", header=None)\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"⚠️ Error reading {input_file}: {e}\")\n",
    "    elif ext == \"csv\":\n",
    "        return pd.read_csv(input_file, header=None)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file type: {ext}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5d4d4e0e91bb990",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:07:34.883551Z",
     "start_time": "2025-06-01T10:07:34.879839Z"
    }
   },
   "outputs": [],
   "source": [
    "class HeaderDetector:\n",
    "    \"\"\"\n",
    "    A class to detect headers in a bank statement.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def match_expected_to_actual(actual_headers):\n",
    "        matches = []\n",
    "\n",
    "        # Step 1: Create (expected_key, actual_header, score) triples\n",
    "        for expected_key, alias_list in expected_headers.items():\n",
    "            for actual in actual_headers:\n",
    "                score = max(fuzz.partial_ratio(actual.lower(), alias.lower()) for alias in alias_list)\n",
    "                matches.append((expected_key, actual, score))\n",
    "\n",
    "        # Step 2: Sort by score descending\n",
    "        matches.sort(key=lambda x: x[2], reverse=True)\n",
    "\n",
    "        # Step 3: Greedily assign best matches\n",
    "        used_actual_headers = set()\n",
    "        assigned_keys = set()\n",
    "        final_mapping = {}\n",
    "\n",
    "        for expected_key, actual, score in matches:\n",
    "            if actual not in used_actual_headers and expected_key not in assigned_keys:\n",
    "                final_mapping[expected_key] = actual\n",
    "                used_actual_headers.add(actual)\n",
    "                assigned_keys.add(expected_key)\n",
    "\n",
    "        # Swap keys and values to get actual_to_standard mapping\n",
    "        final_mapping = {v: k for k, v in final_mapping.items()}\n",
    "\n",
    "        return final_mapping\n",
    "\n",
    "    @staticmethod\n",
    "    def find_header_row(df, start_row):\n",
    "        best_idx, best_score = None, -1\n",
    "        for i in range(max(0, start_row - 3), start_row):\n",
    "            row_cells = df.iloc[i].astype(str).str.lower().tolist()\n",
    "            category_scores = []\n",
    "            for hdr_terms in expected_headers.values():\n",
    "                term_score = max(\n",
    "                    fuzz.partial_ratio(cell, term)\n",
    "                    for cell in row_cells\n",
    "                    for term in hdr_terms\n",
    "                )\n",
    "                category_scores.append(term_score)\n",
    "            avg_score = sum(category_scores) / len(category_scores)\n",
    "            if avg_score > best_score:\n",
    "                best_score, best_idx = avg_score, i\n",
    "        return best_idx\n",
    "\n",
    "    @staticmethod\n",
    "    def score_header_row(row_values):\n",
    "        category_scores = []\n",
    "        for hdr_terms in expected_headers.values():\n",
    "            term_score = max(\n",
    "                fuzz.partial_ratio(cell, term)\n",
    "                for cell in row_values\n",
    "                for term in hdr_terms\n",
    "            )\n",
    "            category_scores.append(term_score)\n",
    "        return sum(category_scores) / len(category_scores)\n",
    "\n",
    "    @staticmethod\n",
    "    def find_best_header(df, first_txn_idx, scan_top_n=50):\n",
    "        # Bottom-up\n",
    "        bottom_idx = HeaderDetector.find_header_row(df, first_txn_idx)\n",
    "        bottom_row = df.iloc[bottom_idx].astype(str).str.lower().tolist()\n",
    "        bottom_score = HeaderDetector.score_header_row(bottom_row)\n",
    "\n",
    "        # Top-down\n",
    "        best_top_score, best_top_idx = -1, None\n",
    "        for i in range(min(scan_top_n, len(df))):\n",
    "            row = df.iloc[i].astype(str).str.lower().tolist()\n",
    "            score = HeaderDetector.score_header_row(row)\n",
    "            if score > best_top_score:\n",
    "                best_top_score = score\n",
    "                best_top_idx = i\n",
    "\n",
    "        # Pick better\n",
    "        print(f\"Bottom-row {df.iloc[bottom_idx].tolist()}\")\n",
    "        print(f\"Top-row {df.iloc[best_top_idx].tolist()}\")\n",
    "\n",
    "        if best_top_score > bottom_score:\n",
    "            print(f\"🧠 Using top-down header (row {best_top_idx}) with score {best_top_score:.2f}\")\n",
    "            print(f\"Bottom-up header (row {bottom_idx}) had score {bottom_score:.2f}\")\n",
    "            return best_top_idx\n",
    "        else:\n",
    "            print(f\"🔍 Using bottom-up header (row {bottom_idx}) with score {bottom_score:.2f}\")\n",
    "            print(f\"Top-down header (row {best_top_idx}) had score {best_top_score:.2f}\")\n",
    "            return bottom_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8496d2b124bdd21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:07:35.051785Z",
     "start_time": "2025-06-01T10:07:35.044250Z"
    }
   },
   "outputs": [],
   "source": [
    "class BankStatementParser:\n",
    "    output_file = None\n",
    "    input_dir = None\n",
    "\n",
    "    def __init__(self, input_dir, output_file):\n",
    "        self.input_dir = input_dir\n",
    "        self.output_file = output_file\n",
    "\n",
    "    def process(self):\n",
    "        all_valid_rows = []\n",
    "        print(\"Processing bank statement...\")\n",
    "        print(\"Input directory:\", self.input_dir)\n",
    "        for file in os.listdir(self.input_dir):\n",
    "            print(\"🔍 Checking file:\", file)\n",
    "            if not file.endswith(('.xls', '.xlsx', '.csv')):\n",
    "                continue\n",
    "            print(\"🔍 Processing file:\", file)\n",
    "            file_path = os.path.join(self.input_dir, file)\n",
    "\n",
    "            df = robust_load(file_path)\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"⚠️ Skipping {file}: No data loaded.\")\n",
    "                continue\n",
    "\n",
    "            first_txn_idx = None\n",
    "            for i, row in df.iterrows():\n",
    "                if TransactionValidator.is_valid_transaction_row(row):\n",
    "                    first_txn_idx = i\n",
    "                    break\n",
    "\n",
    "            if first_txn_idx is None:\n",
    "                continue\n",
    "\n",
    "            header_idx = HeaderDetector.find_best_header(df, first_txn_idx)\n",
    "            headers = df.iloc[header_idx].tolist()\n",
    "            # Trim the headers to remove leading/trailing whitespace\n",
    "            headers = [header.strip() for header in headers if isinstance(header, str)]\n",
    "            data_df = df.iloc[header_idx + 1:].reset_index(drop=True)\n",
    "            data_df.columns = headers\n",
    "            print(f\"✅ Detected header row at index {header_idx}: {headers}\")\n",
    "\n",
    "            actual_to_standard = HeaderDetector.match_expected_to_actual(data_df.columns)\n",
    "\n",
    "            print(f\"🔍 Mapped columns: {actual_to_standard}\")\n",
    "\n",
    "            valid_rows = [row for _, row in data_df.iterrows() if TransactionValidator.is_valid_transaction_row(row)]\n",
    "            if not valid_rows:\n",
    "                continue\n",
    "\n",
    "            partial_df = pd.DataFrame(valid_rows, columns=data_df.columns)[list(actual_to_standard.keys())]\n",
    "            partial_df = partial_df.rename(columns=actual_to_standard)\n",
    "            print(partial_df.head())\n",
    "            partial_df[\"description\"] = partial_df[\"description\"].astype(str).apply(mask_all_digits)\n",
    "            partial_df[\"date\"] = partial_df[\"date\"].apply(normalize_date)\n",
    "\n",
    "            partial_df = partial_df[[\"date\", \"description\", \"credit\", \"debit\"]]\n",
    "            print(f\"✅ Processed {file}: {len(partial_df)} valid rows found.\")\n",
    "            all_valid_rows.append(partial_df)\n",
    "\n",
    "        if not all_valid_rows:\n",
    "            print(\"⚠️ No valid transactions found across all files.\")\n",
    "            return\n",
    "\n",
    "        final_df = pd.concat(all_valid_rows, ignore_index=True)\n",
    "        final_df.to_csv(self.output_file, index=False)\n",
    "        print(f\"✅ Consolidated {len(final_df)} valid rows into {self.output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff7b2a21df06c524",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:13:19.432024Z",
     "start_time": "2025-06-01T10:13:19.425475Z"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = BankStatementParser(\"../bank_statements\", \"../output/consolidated_output.csv\")\n",
    "    parser.process()"
   ]
  },
  {
   "cell_type": "code",
   "id": "7348a4774789fdbf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:28:08.444626Z",
     "start_time": "2025-06-01T10:28:08.202796Z"
    }
   },
   "source": "",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing bank statement...\n",
      "Input directory: ../bank_statements\n",
      "🔍 Checking file: .DS_Store\n",
      "🔍 Checking file: bank_statement2.xlsx\n",
      "🔍 Processing file: bank_statement2.xlsx\n",
      "🔍 Loading file: ../bank_statements/bank_statement2.xlsx\n",
      "Bottom-row ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', '        Debit', 'Credit', 'Balance']\n",
      "Top-row ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', '        Debit', 'Credit', 'Balance']\n",
      "🔍 Using bottom-up header (row 20) with score 100.00\n",
      "Top-down header (row 20) had score 100.00\n",
      "✅ Detected header row at index 20: ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', 'Debit', 'Credit', 'Balance']\n",
      "🔍 Mapped columns: {'Txn Date': 'date', 'Description': 'description', 'Debit': 'debit', 'Credit': 'credit'}\n",
      "        date                                        description     debit  \\\n",
      "0 2024-09-01     ATM WDL-ATM CASH 8346  ANJANAPURA BANGALORE...     10000   \n",
      "1 2024-09-01     ATM WDL-ATM CASH 8347  ANJANAPURA BANGALORE...     10000   \n",
      "2 2024-09-01                              BY TRANSFER-INB pgr--             \n",
      "3 2024-09-02     TO TRANSFER-UPI/DR/424661211772/CRED/UTIB/c...  70592.44   \n",
      "4 2024-09-02                              BY TRANSFER-INB pgr--             \n",
      "\n",
      "   credit  \n",
      "0          \n",
      "1          \n",
      "2  100000  \n",
      "3          \n",
      "4   50000  \n",
      "✅ Processed bank_statement2.xlsx: 299 valid rows found.\n",
      "🔍 Checking file: bank_statement.xls\n",
      "🔍 Processing file: bank_statement.xls\n",
      "🔍 Loading file: ../bank_statements/bank_statement.xls\n",
      "Bottom-row ['Date', 'Narration', 'Chq./Ref.No.', 'Value Dt', 'Withdrawal Amt.', 'Deposit Amt.', 'Closing Balance']\n",
      "Top-row ['Date', 'Narration', 'Chq./Ref.No.', 'Value Dt', 'Withdrawal Amt.', 'Deposit Amt.', 'Closing Balance']\n",
      "🔍 Using bottom-up header (row 20) with score 100.00\n",
      "Top-down header (row 20) had score 100.00\n",
      "✅ Detected header row at index 20: ['Date', 'Narration', 'Chq./Ref.No.', 'Value Dt', 'Withdrawal Amt.', 'Deposit Amt.', 'Closing Balance']\n",
      "🔍 Mapped columns: {'Date': 'date', 'Narration': 'description', 'Withdrawal Amt.': 'debit', 'Deposit Amt.': 'credit'}\n",
      "       date                                        description   debit  \\\n",
      "1  01/01/25  UPI-P SAI DEEKSHITH-DEEKSHITHSAI39@OKSBI-SBIN0...     NaN   \n",
      "2  03/01/25  UPI-INDIAN CLEARING CORP-MUTUALFUNDS.ELEMENTS@...  4000.0   \n",
      "3  03/01/25  UPI-INDIAN CLEARING CORP-MUTUALFUNDS.ELEMENTS@...  7000.0   \n",
      "4  03/01/25  UPI-INDIAN CLEARING CORP-MUTUALFUNDS.ELEMENTS@...  5000.0   \n",
      "5  03/01/25  UPI-INDIAN CLEARING CORP-MUTUALFUNDS.ELEMENTS@...  3000.0   \n",
      "\n",
      "     credit  \n",
      "1  10723.77  \n",
      "2       NaN  \n",
      "3       NaN  \n",
      "4       NaN  \n",
      "5       NaN  \n",
      "✅ Processed bank_statement.xls: 30 valid rows found.\n",
      "🔍 Checking file: bank_statement1.xls\n",
      "🔍 Processing file: bank_statement1.xls\n",
      "🔍 Loading file: ../bank_statements/bank_statement1.xls\n",
      "Bottom-row ['Date', 'Narration', 'Chq./Ref.No.', 'Value Dt', 'Withdrawal Amt.', 'Deposit Amt.', 'Closing Balance']\n",
      "Top-row ['Date', 'Narration', 'Chq./Ref.No.', 'Value Dt', 'Withdrawal Amt.', 'Deposit Amt.', 'Closing Balance']\n",
      "🔍 Using bottom-up header (row 20) with score 100.00\n",
      "Top-down header (row 20) had score 100.00\n",
      "✅ Detected header row at index 20: ['Date', 'Narration', 'Chq./Ref.No.', 'Value Dt', 'Withdrawal Amt.', 'Deposit Amt.', 'Closing Balance']\n",
      "🔍 Mapped columns: {'Date': 'date', 'Narration': 'description', 'Withdrawal Amt.': 'debit', 'Deposit Amt.': 'credit'}\n",
      "       date                                        description     debit  \\\n",
      "1  02/04/24  DEBIT CARD ANNUAL FEE-MAR-2024 160324-MIR25092...    243.05   \n",
      "2  03/04/24             ACH D- TPCAPFRST IDFC FIRST-1402131471  13542.00   \n",
      "3  03/04/24  UPI-AMAZON INDIA-AMAZON@YAPL-YESB0APLUPI-40940...   2189.00   \n",
      "4  03/04/24  UPI-P SAI DEEKSHITH-DEEKSHITHSAI39@OKICICI-SBI...       NaN   \n",
      "5  03/04/24  UPI-CAPITALFLOAT-AMZNLPA-NUQCORICOX@APL-UTIB00...   3798.00   \n",
      "\n",
      "    credit  \n",
      "1      NaN  \n",
      "2      NaN  \n",
      "3      NaN  \n",
      "4  14000.0  \n",
      "5      NaN  \n",
      "✅ Processed bank_statement1.xls: 313 valid rows found.\n",
      "🔍 Checking file: bank_statement3.xlsx\n",
      "🔍 Processing file: bank_statement3.xlsx\n",
      "🔍 Loading file: ../bank_statements/bank_statement3.xlsx\n",
      "Bottom-row ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', '        Debit', 'Credit', 'Balance']\n",
      "Top-row ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', '        Debit', 'Credit', 'Balance']\n",
      "🔍 Using bottom-up header (row 20) with score 100.00\n",
      "Top-down header (row 20) had score 100.00\n",
      "✅ Detected header row at index 20: ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', 'Debit', 'Credit', 'Balance']\n",
      "🔍 Mapped columns: {'Txn Date': 'date', 'Description': 'description', 'Debit': 'debit', 'Credit': 'credit'}\n",
      "        date                                        description    debit  \\\n",
      "0 2023-04-01     BY TRANSFER-UPI/CR/345764776060/SHREE SH/SB...            \n",
      "1 2023-04-02     TO TRANSFER-UPI/DR/309208722561/BHARTI A/AI...  1688.68   \n",
      "2 2023-04-02     DEBIT-CMP MANDATE DEBIT Bajaj Finance Ltd. ...    26167   \n",
      "3 2023-04-02     DEBIT-ACHDr NACH00000000013149 IDFCFIRSTBANK--    17417   \n",
      "4 2023-04-02     TO TRANSFER-UPI/DR/309243779692/KAKAL KA/IC...       58   \n",
      "\n",
      "  credit  \n",
      "0  40000  \n",
      "1         \n",
      "2         \n",
      "3         \n",
      "4         \n",
      "✅ Processed bank_statement3.xlsx: 299 valid rows found.\n",
      "🔍 Checking file: bank_statement4.xlsx\n",
      "🔍 Processing file: bank_statement4.xlsx\n",
      "🔍 Loading file: ../bank_statements/bank_statement4.xlsx\n",
      "Bottom-row ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', '        Debit', 'Credit', 'Balance']\n",
      "Top-row ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', '        Debit', 'Credit', 'Balance']\n",
      "🔍 Using bottom-up header (row 20) with score 100.00\n",
      "Top-down header (row 20) had score 100.00\n",
      "✅ Detected header row at index 20: ['Txn Date', 'Value Date', 'Description', 'Ref No./Cheque No.', 'Debit', 'Credit', 'Balance']\n",
      "🔍 Mapped columns: {'Txn Date': 'date', 'Description': 'description', 'Debit': 'debit', 'Credit': 'credit'}\n",
      "        date                                        description debit credit\n",
      "0 2024-04-02     TO TRANSFER-UPI/DR/445965335535/hsbahuba/UB...  5000       \n",
      "1 2024-04-02     TO TRANSFER-UPI/DR/445967104550/ARIHANTH/UB...  5000       \n",
      "2 2024-04-02     DEBIT-ACHDr NACH00000000013149 RAZORPAYSOFT...  9767       \n",
      "3 2024-04-02     TO TRANSFER-UPI/DR/409316322038/manjuman/CN...  3300       \n",
      "4 2024-04-02                              BY TRANSFER-INB pgr--        70000\n",
      "✅ Processed bank_statement4.xlsx: 299 valid rows found.\n",
      "✅ Consolidated 1240 valid rows into ../output/consolidated_output.csv\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbe789473fd8da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-01T10:07:36.755465Z",
     "start_time": "2025-06-01T10:07:36.753504Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
